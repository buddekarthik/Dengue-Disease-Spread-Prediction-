{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "xt = pd.read_csv('dengue_features_train.csv')\n",
    "yt = pd.read_csv('dengue_labels_train.csv')\n",
    "wt = pd.read_csv('dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xt.iloc[:,4:].values\n",
    "y = yt.iloc[:, 3].values\n",
    "w = wt.iloc[:,4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "imputer = imputer.fit(w)\n",
    "w = imputer.transform(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressor - Two-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_rmse_LR = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "test_set_r2_LR = r2_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.4193369908355\n",
      "0.12752591219727538\n"
     ]
    }
   ],
   "source": [
    "print(test_set_rmse_LR)\n",
    "print(test_set_r2_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that for rmse, the lower that value is, the better the fit\n",
    "\n",
    "# The closer towards 1, the better the fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier()\n",
    "MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MLP.predict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_rmse_MLP = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "test_set_r2_MLP = r2_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Accuracy score for MLP:  61.64383561643835 \n",
      "\n",
      "*Confusion Matrix for MLP: \n",
      "[[7 0 1 ... 0 0 0]\n",
      " [3 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "*Classification Report for MLP: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.35      0.25        20\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.05      0.15      0.07        13\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.08      0.44      0.13        16\n",
      "           6       0.09      0.05      0.06        20\n",
      "           7       0.04      0.08      0.05        13\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         4\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         2\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         104       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         1\n",
      "         381       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.06       292\n",
      "   macro avg       0.01      0.01      0.01       292\n",
      "weighted avg       0.03      0.06      0.03       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = MLP.predict(X_test)\n",
    "val4 = (accuracy_score(y_test, predictions)*100)\n",
    "print(\"*Accuracy score for MLP: \", val4*10, \"\\n\")\n",
    "print(\"*Confusion Matrix for MLP: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Report for MLP: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions = SVM.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Accuracy score for SVM:  68.4931506849315 \n",
      "\n",
      "*Confusion Matrix for SVM: \n",
      "[[20  0  0 ...  0  0  0]\n",
      " [15  0  0 ...  0  0  0]\n",
      " [17  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]]\n",
      "*Classification Report for SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      1.00      0.13        20\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.00      0.00      0.00        13\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         4\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         5\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         2\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         1\n",
      "         381       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.07       292\n",
      "   macro avg       0.00      0.01      0.00       292\n",
      "weighted avg       0.00      0.07      0.01       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "val1 = (accuracy_score(y_test, predictions)*100)\n",
    "print(\"*Accuracy score for SVM: \", val1*10, \"\\n\")\n",
    "print(\"*Confusion Matrix for SVM: \")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"*Classification Report for SVM: \")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB - Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "xgb = XGBRegressor(n_estimators=100)\n",
    "xgb.fit(X_train,y_train)\n",
    "pred = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "mse = []\n",
    "mae = []\n",
    "rmse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1344.44]\n",
      "[21.8]\n",
      "[36.67]\n"
     ]
    }
   ],
   "source": [
    "models.append('XGBoost')\n",
    "mse.append(round(mean_squared_error(pred, y_test),2))\n",
    "mae.append(round(mean_absolute_error(pred, y_test),2))\n",
    "rmse.append(round(np.sqrt(mean_squared_error(pred, y_test)),2))\n",
    "print(mse)\n",
    "print(mae)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_r2_XGB = r2_score(y_test, y_pred)\n",
    "#print(test_set_r2_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor(n_estimators=300,random_state=0)\n",
    "RF.fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting a new result\n",
    "y_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_rmse_RF = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "test_set_r2_RF = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.768855556128678\n",
      "0.9080777866929082\n"
     ]
    }
   ],
   "source": [
    "print(test_set_rmse_RF)\n",
    "print(test_set_r2_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bring some raw data.\n",
    "frequencies = [val1/100,val4/100,test_set_r2_RF,test_set_r2_LR]\n",
    "\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series(frequencies)\n",
    "\n",
    "x_labels = ['SVM', 'MLP','RF-Reg','Linear Regression']\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = freq_series.plot(kind='bar')\n",
    "ax.set_title('Evaluation of ML & DL')\n",
    "ax.set_xlabel('Classifier!')\n",
    "ax.set_ylabel('Accuracy Range')\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values.\n",
    "\n",
    "\n",
    "# Call the function above. All the magic happens there.\n",
    "add_value_labels(ax)\n",
    "plt.show()\n",
    "#plt.savefig(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.pkl'\n",
    "pickle.dump(RF, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from werkzeug.wrappers import Request, Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@app.route('/predict_api',methods=['POST'])\\ndef predict_api():\\n    '''\\n    For direct API calls trought request\\n    '''\\n    data = request.get_json(force=True)\\n    prediction = model.predict([np.array(list(data.values()))])\\n\\n    output = prediction[0]\\n    return jsonify(output)\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "model = pickle.load(open('model.pkl', 'rb'))\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('home.html')\n",
    "\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "@app.route('/about')\n",
    "def about():\n",
    "    return render_template('About.html')\n",
    "\n",
    "@app.route('/dd')  \n",
    "def dd():\n",
    "    return render_template('Disease Description.html')\n",
    "\n",
    "@app.route('/maps')\n",
    "def maps():\n",
    "    return render_template('Maps.html')\n",
    "\n",
    "@app.route('/prediction')\n",
    "def prediction():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    '''\n",
    "    For rendering results on HTML GUI\n",
    "    '''\n",
    "    int_features = [str(x) for x in request.form.values()]\n",
    "    #a=float(int_features[-2])\n",
    "    #int_features1 = int_features\n",
    "    #int_features[0] = x_label.transform(np.array([int_features[0]]))\n",
    "    #int_features = onehotencoder.transform([int_features]).toarray()\n",
    "    #int_features = int_features[1:]\n",
    "    #for i in int_features:\n",
    "     #  int_features1.append(float(i)) \n",
    "    #final_features = int_features\n",
    "\n",
    "    prediction = model.predict(np.array(int_features).reshape(1,-1))\n",
    "    output = round(prediction[0], 2)    \n",
    "    \n",
    "    #output = round(prediction[0]*100000, 2)\n",
    "\n",
    "    return render_template('index.html', prediction_text='Number of cases till then will be :{}'.format(output))\n",
    "\n",
    "@app.route('/visual')\n",
    "def visual():\n",
    "    return render_template('visualize.html')\n",
    "\n",
    "\"\"\"@app.route('/predict_api',methods=['POST'])\n",
    "def predict_api():\n",
    "    '''\n",
    "    For direct API calls trought request\n",
    "    '''\n",
    "    data = request.get_json(force=True)\n",
    "    prediction = model.predict([np.array(list(data.values()))])\n",
    "\n",
    "    output = prediction[0]\n",
    "    return jsonify(output)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:20] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:21] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:23] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:26] \"\u001b[37mGET /prediction HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:26] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:22:26] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:23:33] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:23:33] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:26] \"\u001b[37mGET /dd HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:27] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:54] \"\u001b[37mGET /maps HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2000.jpeg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2001.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2002.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2003.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2004.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2010.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2010.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2015.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/2018.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/images.jpeg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:24:55] \"\u001b[37mGET /static/images/pie.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:25:05] \"\u001b[37mGET /prediction HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:25:05] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:28:16] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2021 15:28:17] \"\u001b[33mGET /static/css/static/images/background.jpg HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
